% --- chapters/chapter3.tex ---
% Generated by Gemini (Google AI) on 2025-04-04.
% Contains extracted items from W. Rudin, PMA, Chapter 3.
% Assumes macros like \sequence{}, \R, \C, \abs{}, \norm{}, \vect{} are defined.
% Proofs are omitted as requested.

\chapter{Numerical Sequences and Series}
\label{chap:rudin3}

\section{Convergent Sequences}
\label{sec:chap3:convergence}

\begin{definition}[Convergent Sequence] % Definition 3.1
  \label{def:chap3:convergent_sequence}
  A sequence $\sequence{p}$ in a metric space $X$ is said to
  \emph{converge} if there is a point $p \in X$ with the following
  property: For every $\epsilon > 0$ there is an integer N such that
  $n \ge N$ implies $d(p_n, p) < \epsilon$.
  (Here $d$ denotes the distance in X.)
  In this case we also say that $\sequence{p}$ converges to p, or
  that p is the limit of $\sequence{p}$, and we write $p_n \to p$, or
  \[ \lim_{n \to \infty} p_n = p. \]
  If $\sequence{p}$ does not converge, it is said to \emph{diverge}.
  The set of all points $p_n$ ($n=1, 2, 3, \dots$) is the range of
  the sequence. The range of a sequence may be a finite set, or it
  may be infinite. The sequence $\sequence{p}$ is said to be bounded
  if its range is bounded (\autoref{def:chap2:bounded_set}).
  As examples, consider the following sequences of complex numbers
  (i.e., $X = \R^2 = \C$):
  (a) If $s_n = 1/n$, then $\lim_{n \to \infty} s_n = 0$. The range
  is infinite, and the sequence is bounded.
  (b) If $s_n = n^2$, the sequence $\sequence{s}$ is divergent. The
  range is infinite, and the sequence is unbounded.
  (c) If $s_n = 1 + (-1)^n / n$, the sequence $\sequence{s}$
  converges to 1. The range is infinite, and the sequence is bounded.
  Range: $\{0, 3/2, 2/3, 5/4, 4/5, ...\}$.
  (d) If $s_n = i^n$, the sequence $\sequence{s}$ is divergent. The
  range is finite: $\{i, -1, -i, 1\}$. The sequence is bounded.
  (e) If $s_n = 1$ ($n = 1, 2, 3, \dots$), then $\sequence{s}$
  converges to 1. The range is finite: $\{1\}$. The sequence is bounded.
\end{definition}

\begin{theorem}[Convergent Sequence Properties] % Theorem 3.2
  \label{thm:chap3:convergent_props}
  Let $\sequence{p}$ be a sequence in a metric space X.
  (a) $\sequence{p}$ converges to $p \in X$ if and only if every
  neighborhood of p contains $p_n$ for all but finitely many n.
  (b) If $p \in X$, $p' \in X$, and if $\sequence{p}$ converges to p
  and to $p'$, then $p=p'$. (Uniqueness of Limit)
  (c) If $\sequence{p}$ converges, then $\sequence{p}$ is bounded.
  (d) If $E \subset X$ and if p is a limit point of E, then there is
  a sequence $\sequence{p}$ in E such that $p_n \to p$.
  % Proof Omitted
\end{theorem}

\begin{theorem}[Convergence in C and Rk] % Theorem 3.3
  \label{thm:chap3:convergence_C_Rk}
  Suppose $\sequence{s}$, $\sequence{t}$ are complex sequences, and
  $\lim_{n \to \infty} s_n = s$, $\lim_{n \to \infty} t_n = t$. Then
  (a) $\lim_{n \to \infty} (s_n + t_n) = s+t$;
  (b) $\lim_{n \to \infty} c \cdot s_n = c \cdot s$, $\lim_{n \to
  \infty} (c + s_n) = c + s$, for any number c;
  (c) $\lim_{n \to \infty} (s_n t_n) = st$;
  (d) $\lim_{n \to \infty} \frac{1}{s_n} = \frac{1}{s}$, provided
  $s_n \ne 0$ ($n=1, 2, 3, \dots$) and $s \ne 0$.
  These statements are also true if $\sequence{s}$, $\sequence{t}$
  are sequences in $\R^k$, and sums and products are interpreted as
  vector sums and inner products (\autoref{def:chap1:euclidean_k_space}).
  % Proof Omitted (uses triangle inequality from Thm 1.33/1.37 and
  % boundedness from Thm 3.2)
\end{theorem}

% --- End of content chunk ---

% --- Content from Thm 3.4 to Thm 3.7 (Proofs Omitted) to append ---

\begin{theorem}[Squeeze Theorem] % Theorem 3.4
  \label{thm:chap3:squeeze_theorem}
  (a) Suppose $\sequence{s}$, $\sequence{t}$ are real sequences, and
  $s_n \le t_n$ for $n \ge N$ (where N is some fixed number). Then
  \[ \lim_{n \to \infty} s_n = s, \quad \lim_{n \to \infty} t_n = t \]
  implies $s \le t$.
  (b) Suppose $\sequence{s}$, $\sequence{t}$, $\sequence{u}$ are real
  sequences, $s_n \le t_n \le u_n$ for $n \ge N$, and $\lim_{n \to
  \infty} s_n = \lim_{n \to \infty} u_n = L$. Then $\lim_{n \to
  \infty} t_n = L$.
  % Proof Omitted
\end{theorem}

\begin{theorem}[Convergence via Components/Parts] % Theorem 3.5
  \label{thm:chap3:convergence_components}
  (a) Suppose $\vect{x}_n \in \R^k$ ($n=1, 2, 3, \dots$) and
  $\vect{x}_n = (x_{n,1}, \dots, x_{n,k})$. Then
  $\sequence{\vect{x}}$ converges to $\vect{x} = (x_1, \dots, x_k)$
  if and only if $\lim_{n \to \infty} x_{n,j} = x_j$ for $j=1, \dots, k$.
  (b) Suppose $\sequence{p}$, $\sequence{q}$ are sequences in a
  metric space X, and $d(p_n, q_n) \to 0$. If $\sequence{p}$
  converges to p, then $\sequence{q}$ converges to p.
  % Proof Omitted
\end{theorem}

\section{Subsequences}
\label{sec:chap3:subsequences}

\begin{definition}[Subsequence, Subsequential Limit] % Definition 3.6
  \label{def:chap3:subsequence_sublimit}
  Given a sequence $\sequence{p}$, consider a sequence $\sequence{n}$
  of positive integers such that $n_1 < n_2 < n_3 < \dots$. Then the
  sequence $\sequence{p \circ n}$, whose k-th term is $p_{n_k}$, is
  called a subsequence of $\sequence{p}$. If $\sequence{p \circ n}$
  converges, its limit is called a subsequential limit of $\sequence{p}$.
  It is clear that $\sequence{p}$ converges to p if and only if every
  subsequence of $\sequence{p}$ converges to p.
\end{definition}

\begin{theorem}[Subsequence Properties / Bolzano-Weierstrass] % Theorem 3.7
  \label{thm:chap3:subsequence_props_bw}
  (a) If $\sequence{p}$ is a sequence in a compact metric space X,
  then some subsequence of $\sequence{p}$ converges to a point of X.
  (General Bolzano-Weierstrass)
  (b) Every bounded sequence in $\R^k$ contains a convergent
  subsequence. (Bolzano-Weierstrass for $\R^k$)
  % Proof Omitted (uses Thm 2.37 for (a), Thm 2.41/3.2(c) for (b))
\end{theorem}

% --- End of content chunk ---

% --- Content from Thm 3.8 to Def 3.13 (Proofs Omitted) to append ---

\begin{theorem}[Subsequential Limits Form Closed Set] % Theorem 3.8
  \label{thm:chap3:sublimits_closed}
  The subsequential limits of a sequence $\sequence{p}$ in a metric
  space X form a closed subset of X.
  % Proof Omitted
\end{theorem}

\begin{theorem}[Existence of LimSup/LimInf for Real Sequences] % Theorem 3.9
  \label{thm:chap3:bounded_seq_lim_sup_inf_exist}
  If $\sequence{s}$ is a bounded sequence in $\R$, let E be the set
  of all subsequential limits of $\sequence{s}$. Let $s^* = \sup E$
  and $s_* = \inf E$. Then $s^*$ and $s_*$ are in E.
  (These numbers $s^*$ and $s_*$ are called the upper and lower
  limits of $\sequence{s}$; see Definition 3.16)
  % Proof Omitted (Uses Thm 3.7, Thm 2.28)
\end{theorem}

\section{Cauchy Sequences}
\label{sec:chap3:cauchy_sequences}

\begin{definition}[Cauchy Sequence] % Definition 3.10
  \label{def:chap3:cauchy_sequence}
  A sequence $\sequence{p}$ in a metric space X is said to be a
  \emph{Cauchy sequence} if for every $\epsilon > 0$ there is an
  integer N such that $d(p_n, p_m) < \epsilon$ if $n \ge N$ and $m \ge N$.
  In our discussion of Cauchy sequences, as well as in other
  situations which will arise later, the following geometric concept
  will be useful.
\end{definition}

\begin{definition}[Diameter, Boundedness] % Definition 3.11
  \label{def:chap3:diameter_bounded}
  Let E be a nonempty subset of a metric space X, and let $S$ be the
  set of all real numbers of the form $d(p, q)$, with $p \in E$ and
  $q \in E$. The supremum of S is called the \emph{diameter} of E.
  If $\sequence{p}$ is a sequence in X and if $E_N$ consists of the
  points $p_N, p_{N+1}, p_{N+2}, \dots$, it is clear from the two
  preceding definitions that $\sequence{p}$ is a Cauchy sequence if and only if
  \[ \lim_{N \to \infty} \text{diam } E_N = 0. \]
  A set E is bounded (\autoref{def:chap2:bounded_set}) if and only if
  its diameter is finite.
\end{definition}

\begin{theorem}[Cauchy Sequence Properties] % Theorem 3.12
  \label{thm:chap3:cauchy_props}
  (a) If $\overline{E}$ is the closure of a set E in a metric space
  X, then $\text{diam } \overline{E} = \text{diam } E$.
  (b) If $K_n$ is a sequence of compact sets in X
  (\autoref{def:chap2:compact_set}) such that $K_n \supset K_{n+1}$
  ($n=1, 2, 3, \dots$) and if $\lim_{n \to \infty} \text{diam } K_n =
  0$, then $\bigcap_{n=1}^\infty K_n$ contains exactly one point.
  (c) In any metric space X, every convergent sequence is a Cauchy sequence.
  (d) If X is a compact metric space and if $\sequence{p}$ in X is a
  Cauchy sequence, then $\sequence{p}$ converges to some point of X.
  (e) In $\R^k$, every Cauchy sequence converges.
  (Compare (e) with \autoref{thm:chap3:completeness_Rk}.)
  % Proof Omitted
\end{theorem}

\begin{definition}[Complete Metric Space] % Definition 3.13
  \label{def:chap3:complete_metric_space}
  A metric space X in which every Cauchy sequence converges is said
  to be \emph{complete}.
  Note: All compact metric spaces are complete
  (\autoref{thm:chap3:cauchy_props}(d)). $\R^k$ is complete
  (\autoref{thm:chap3:cauchy_props}(e)). A nonempty subset of a
  complete space may fail to be complete (e.g., the segment (0,1) in $\R^1$).
\end{definition}

% --- End of content chunk ---

% --- Content from Thm 3.14 to Thm 3.17 (Proofs Omitted) to append ---

\begin{theorem}[Completeness of Rk, Subspaces] % Theorem 3.14
  \label{thm:chap3:completeness_Rk}
  (a) Euclidean spaces $\R^k$ are complete metric spaces. (This
  follows from \autoref{thm:chap3:cauchy_props}(e).)
  (b) A subspace Y of a complete metric space X is complete if and
  only if Y is closed.
  % Proof Omitted
\end{theorem}

\begin{theorem}[Monotonic Sequences] % Theorem 3.15
  \label{thm:chap3:monotonic_sequences}
  Suppose $\sequence{s}$ is monotonic. Then $\sequence{s}$ converges
  if and only if it is bounded.
  (This theorem refers to sequences of real numbers. Monotonic means
    either monotonically increasing ($s_n \le s_{n+1}$) or
  monotonically decreasing ($s_n \ge s_{n+1}$) for all n.)
  % Proof Omitted
\end{theorem}

\section{Upper and Lower Limits}
\label{sec:chap3:lim_sup_inf}

\begin{definition}[Upper and Lower Limits] % Definition 3.16
  \label{def:chap3:lim_sup_inf}
  Let $\sequence{s}$ be a sequence of real numbers. Let E be the set
  of numbers x (in the extended real number system
  \autoref{def:chap1:extended_real_numbers}) such that $s_{n_k} \to
  x$ for some subsequence $\sequence{s \circ n}$. This set E contains
  all subsequential limits as defined in
  \autoref{def:chap3:subsequence_sublimit}, plus possibly the
  elements $+\infty$, $-\infty$.
  We now recall \autoref{thm:chap3:bounded_seq_lim_sup_inf_exist} and define
  \begin{align*}
    s^* &= \sup E \\
    s_* &= \inf E
  \end{align*}
  The numbers $s^*$ and $s_*$ are called the upper and lower limits
  of $\sequence{s}$; we use the notation
  \[ \limsup_{n \to \infty} s_n = s^*, \qquad \liminf_{n \to \infty}
  s_n = s_*. \]
  (Using the macros: $\limsup_{n \to \infty} s_n = s^*$, $\liminf_{n
  \to \infty} s_n = s_*$.)
\end{definition}

\begin{theorem}[Properties of LimSup/LimInf] % Theorem 3.17
  \label{thm:chap3:lim_sup_inf_props}
  Let $\sequence{s}$ be a sequence of real numbers. Let E be the set
  of all subsequential limits of $\sequence{s}$, and let $s^* =
  \limsup_{n \to \infty} s_n$, $s_* = \liminf_{n \to \infty} s_n$. Then
  (a) $s^* \in E$.
  (b) If $x > s^*$, there is an integer N such that $n \ge N$ implies $s_n < x$.
  (c) $s^*$ is the unique number with the properties (a) and (b).
  (d) Analogous results hold for $s_*$.
  (e) $\sequence{s}$ converges to s if and only if $s^* = s_* = s$.
  % Proof Omitted (Relies on Thm 3.7, Thm 3.8)
\end{theorem}

% --- End of content chunk ---

% --- Content from Thm 3.19 to Thm 3.25 (Proofs Omitted) to append ---

\begin{theorem}[LimSup/LimInf of Sums] % Theorem 3.19
  \label{thm:chap3:limsup_sum}
  If $\sequence{s}$ and $\sequence{t}$ are real sequences, then
  \[ \liminf_{n \to \infty} s_n + \liminf_{n \to \infty} t_n \le
  \liminf_{n \to \infty} (s_n + t_n) \]
  \[ \limsup_{n \to \infty} (s_n + t_n) \le \limsup_{n \to \infty}
  s_n + \limsup_{n \to \infty} t_n \]
  provided the sums on the right are not of the form $\infty - \infty$.
  % Proof Omitted
\end{theorem}

\section{Some Special Sequences}
\label{sec:chap3:special_sequences}

We shall now compute the limits of some sequences which occur frequently.

\begin{theorem}[Limits involving Roots and Ratios] % Theorem 3.20
  \label{thm:chap3:special_limits}
  (a) If $p > 0$, then $\lim_{n \to \infty} \frac{1}{n^p} = 0$.
  (b) If $p > 0$, then $\lim_{n \to \infty} \sqrt[n]{p} = 1$.
  (c) $\lim_{n \to \infty} \sqrt[n]{n} = 1$.
  (d) If $p > 0$ and $\alpha$ is real, then $\lim_{n \to \infty}
  \frac{n^\alpha}{(1+p)^n} = 0$.
  (e) If $\abs{x} < 1$, then $\lim_{n \to \infty} x^n = 0$.
  % Proof Omitted
\end{theorem}

\section{Series}
\label{sec:chap3:series}

\begin{definition}[Series Convergence] % Definition 3.21
  \label{def:chap3:series_convergence}
  Given a sequence $\sequence{a}$, we use the notation $\sum_{n=p}^q
  a_n$ ($p \le q$) to denote the sum $a_p + a_{p+1} + \dots + a_q$.
  With $\sequence{a}$ we associate a sequence $\sequence{s}$, where
  $s_n = \sum_{k=1}^n a_k$. For $\sequence{s}$ we also use the
  symbolic expression
  \[ a_1 + a_2 + a_3 + \dots \]
  or, more concisely,
  \[ \sum_{n=1}^\infty a_n. \]
  The symbol $\sum_{n=1}^\infty a_n$ is called an infinite series, or
  just a series. The numbers $s_n$ are called the partial sums of the
  series. If $\sequence{s}$ converges to s, we say that the series
  converges, and write
  \[ \sum_{n=1}^\infty a_n = s. \]
  The number s is called the sum of the series; but it should be
  clearly understood that s is the limit of a sequence of sums, and
  is not obtained simply by addition.
  If $\sequence{s}$ diverges, the series is said to diverge.
  Sometimes, for convenience of notation, we shall consider series of
  the form $\sum_{n=0}^\infty a_n$. And frequently, when the context
  is clear, we shall write $\sum a_n$ in place of $\sum_{n=1}^\infty a_n$.
\end{definition}

\begin{theorem}[Cauchy Criterion for Series] % Theorem 3.22
  \label{thm:chap3:cauchy_series}
  The series $\sum a_n$ converges if and only if for every $\epsilon
  > 0$ there is an integer N such that
  \[ \abs{ \sum_{k=n}^m a_k } \le \epsilon \]
  if $m \ge n \ge N$.
  (Note that this is the Cauchy condition applied to the sequence of
  partial sums $\sequence{s}$.)
  % Proof Omitted (Relies on Cauchy criterion for sequences and completeness)
\end{theorem}

\begin{theorem}[Necessary Condition for Convergence] % Theorem 3.23
  \label{thm:chap3:term_test_divergence}
  If $\sum a_n$ converges, then $\lim_{n \to \infty} a_n = 0$.
  (The converse is false, e.g., the harmonic series $\sum 1/n$.)
  % Proof Omitted
\end{theorem}

\begin{theorem}[Comparison Test] % Theorem 3.24
  \label{thm:chap3:comparison_test}
  (a) If $\abs{a_n} \le c_n$ for $n \ge N_0$, where $N_0$ is some
  fixed integer, and if $\sum c_n$ converges, then $\sum a_n$ converges.
  (b) If $a_n \ge d_n \ge 0$ for $n \ge N_0$, and if $\sum d_n$
  diverges, then $\sum a_n$ diverges.
  (Part (b) applies only to series of nonnegative terms.)
  % Proof Omitted (Uses Cauchy criterion)
\end{theorem}

\begin{theorem}[Geometric Series] % Theorem 3.25
  \label{thm:chap3:geometric_series}
  If $\abs{x} < 1$, then $\sum_{n=0}^\infty x^n = \frac{1}{1-x}$. If
  $\abs{x} \ge 1$, the series diverges.
  % Proof Omitted
\end{theorem}

% --- End of content chunk ---

% --- Content from Thm 3.26 to Ex 3.35 (Proofs Omitted) to append ---

\section{Series of Nonnegative Terms}
\label{sec:chap3:nonneg_series}

\begin{theorem}[Convergence via Partial Sums] % Theorem 3.26
  \label{thm:chap3:nonneg_conv_bounded_sums}
  If $a_n \ge 0$ for all n, then $\sum a_n$ converges if and only if
  its partial sums form a bounded sequence.
  % Proof Omitted (Uses Thm 3.15)
\end{theorem}

\begin{theorem}[Cauchy Condensation Test] % Theorem 3.27
  \label{thm:chap3:cauchy_condensation}
  Suppose $a_1 \ge a_2 \ge a_3 \ge \dots \ge 0$. Then the series
  $\sum_{n=1}^\infty a_n$ converges if and only if the series
  \[ \sum_{k=0}^\infty 2^k a_{2^k} = a_1 + 2a_2 + 4a_4 + 8a_8 + \dots \]
  converges.
  % Proof Omitted
\end{theorem}

\begin{example}[p-series] % Example 3.28
  \label{ex:chap3:p_series}
  Consider the convergence of $\sum \frac{1}{n^p}$.
  If $p \le 0$, the terms do not tend to 0
  (\autoref{thm:chap3:special_limits}(a)), so the series diverges
  (\autoref{thm:chap3:term_test_divergence}).
  If $p > 0$, the terms $1/n^p$ decrease monotonically. We can use
  the condensation test (\autoref{thm:chap3:cauchy_condensation}). We look at
  \[ \sum_{k=0}^\infty 2^k \frac{1}{(2^k)^p} = \sum_{k=0}^\infty 2^k
  (2^{-p})^k = \sum_{k=0}^\infty (2^{1-p})^k. \]
  This is a geometric series (\autoref{thm:chap3:geometric_series})
  which converges if and only if $2^{1-p} < 1$, which happens if and
  only if $1-p < 0$, i.e., $p>1$.
  Conclusion: $\sum \frac{1}{n^p}$ converges if $p>1$ and diverges if $p \le 1$.
\end{example}

\begin{theorem}[Generalization of Condensation Test] % Theorem 3.29
  \label{thm:chap3:condensation_general}
  If $a_n \ge 0$, $a_n$ is monotonically decreasing, and $\sum a_n$
  converges, then $\lim_{n \to \infty} n a_n = 0$.
  % Proof Omitted
\end{theorem}

\section{The Number e}
\label{sec:chap3:number_e}

\begin{theorem}[Definition and Properties of e] % Theorem 3.30
  \label{thm:chap3:e_definition}
  Let $s_n = (1 + 1/n)^n$.
  (a) The sequence $\sequence{s}$ is monotonically increasing.
  (b) The sequence $\sequence{s}$ is bounded above.
  (c) $\lim_{n \to \infty} s_n$ exists.
  The limit is called e.
  $e = \lim_{n \to \infty} (1 + 1/n)^n$.
  % Proof Omitted
\end{theorem}

\begin{theorem}[Series for e] % Theorem 3.31
  \label{thm:chap3:e_series}
  $e = \sum_{n=0}^\infty \frac{1}{n!}$.
  (Recall $0! = 1$.)
  % Proof Omitted (Shows s_n <= sum <= t_n and relates t_n to s_n)
\end{theorem}

\begin{theorem}[e is Irrational] % Theorem 3.32
  \label{thm:chap3:e_irrational}
  The number e is irrational.
  % Proof Omitted (Assumes e=p/q and derives contradiction)
\end{theorem}

\section{The Root and Ratio Tests}
\label{sec:chap3:root_ratio_tests}

\begin{theorem}[Root Test] % Theorem 3.33
  \label{thm:chap3:root_test}
  Given $\sum a_n$, put $\alpha = \limsup_{n \to \infty} \sqrt[n]{\abs{a_n}}$.
  (a) If $\alpha < 1$, $\sum a_n$ converges.
  (b) If $\alpha > 1$, $\sum a_n$ diverges.
  (c) If $\alpha = 1$, the test gives no information.
  % Proof Omitted
\end{theorem}

\begin{theorem}[Ratio Test] % Theorem 3.34
  \label{thm:chap3:ratio_test}
  The series $\sum a_n$
  (a) converges if $\limsup_{n \to \infty} \abs{\frac{a_{n+1}}{a_n}} < 1$,
  (b) diverges if $\abs{\frac{a_{n+1}}{a_n}} \ge 1$ for all $n \ge
  n_0$, where $n_0$ is some fixed integer. (Note the condition here
    is slightly different from the limsup condition in (a); often the
    simpler condition $\liminf_{n \to \infty} \abs{\frac{a_{n+1}}{a_n}}
  > 1$ is used for divergence).
  If $\liminf_{n \to \infty} \abs{\frac{a_{n+1}}{a_n}} \le 1 \le
  \limsup_{n \to \infty} \abs{\frac{a_{n+1}}{a_n}}$, the test gives
  no information.
  % Proof Omitted
\end{theorem}

\begin{example}[Root/Ratio Test Examples] % Example 3.35
  \label{ex:chap3:root_ratio_examples}
  (a) Consider $\sum n/2^n$. Root test: $\sqrt[n]{n/2^n} =
  \frac{\sqrt[n]{n}}{2} \to \frac{1}{2} < 1$. Converges. Ratio test:
  $\frac{(n+1)/2^{n+1}}{n/2^n} = \frac{n+1}{n} \cdot \frac{1}{2} \to
  \frac{1}{2} < 1$. Converges.
  (b) Consider $\sum 2^n/n!$. Ratio test:
  $\frac{2^{n+1}/(n+1)!}{2^n/n!} = \frac{2}{n+1} \to 0 < 1$.
  Converges. Root test: requires Stirling's approx for $n!$, harder.
  (c) Consider $\sum 1/n$ (harmonic series). Ratio test:
  $\frac{1/(n+1)}{1/n} = \frac{n}{n+1} \to 1$. Inconclusive. Root
  test: $\sqrt[n]{1/n} = 1/\sqrt[n]{n} \to 1$. Inconclusive. (We know
  it diverges from \autoref{ex:chap3:p_series}).
  (d) Consider $\sum (-1)^n / n$. Fails absolute convergence tests.
  (Alternating series test applies, see later).
  (e) Consider $1/2 + 1/3 + 1/2^2 + 1/3^2 + 1/2^3 + 1/3^3 + \dots$.
  $a_{2k-1} = 1/2^k$, $a_{2k} = 1/3^k$.
  $\limsup \sqrt[n]{a_n} = \lim_{k\to\infty} \sqrt[2k-1]{1/2^k} =
  \lim (1/2)^{k/(2k-1)} = 1/\sqrt{2} < 1$. Converges.
  $\liminf \abs{a_{n+1}/a_n}$ uses $a_{2k}/a_{2k-1} = (1/3^k)/(1/2^k)
  = (2/3)^k \to 0$.
  $\limsup \abs{a_{n+1}/a_n}$ uses $a_{2k+1}/a_{2k} =
  (1/2^{k+1})/(1/3^k) = (1/2) (3/2)^k \to \infty$. Ratio test
  inconclusive. Root test is better here.
\end{example}

% --- End of content chunk ---

% --- Content from Thm 3.36 to Thm 3.41 (Proofs Omitted) to append ---

\begin{theorem}[Comparison of Root and Ratio Tests] % Theorem 3.36
  % (Labeled as part of 3.37 in Rudin 3rd Ed.)
  \label{thm:chap3:root_ratio_comparison}
  For any sequence $\{c_n\}$ of positive numbers,
  \[ \liminf_{n \to \infty} \frac{c_{n+1}}{c_n} \le \liminf_{n \to
  \infty} \sqrt[n]{c_n} \]
  \[ \limsup_{n \to \infty} \sqrt[n]{c_n} \le \limsup_{n \to \infty}
  \frac{c_{n+1}}{c_n}. \]
  % Proof Omitted
\end{theorem}

\begin{theorem}[Limit Relation to Tests] % Theorem 3.37 in Rudin 3rd
  % Ed. (incorporates 3.36)
  \label{thm:chap3:limit_relation_tests}
  If the sequence $\{\abs{a_{n+1}/a_n}\}$ converges, then its limit
  is equal to $\lim \sqrt[n]{\abs{a_n}}$ (if this limit exists; the
  theorem implies it often does when the ratio limit exists).
  \autoref{thm:chap3:root_ratio_comparison} shows that the root test
  (\autoref{thm:chap3:root_test}) is more general than the ratio test
  (\autoref{thm:chap3:ratio_test}).
  % Statement combined from Rudin's text around Thm 3.37.
\end{theorem}

\section{Power Series}
\label{sec:chap3:power_series}

\begin{definition}[Power Series] % Definition 3.38
  \label{def:chap3:power_series}
  Given a sequence $\sequence{c}$ of complex numbers, the series
  \[ \sum_{n=0}^\infty c_n z^n \]
  is called a power series. The numbers $c_n$ are called the
  coefficients of the series.
\end{definition}

\begin{theorem}[Radius of Convergence] % Theorem 3.39
  \label{thm:chap3:radius_convergence}
  Given the power series $\sum c_n z^n$, put
  \[ \alpha = \limsup_{n \to \infty} \sqrt[n]{\abs{c_n}}, \quad R =
  \frac{1}{\alpha}. \]
  (If $\alpha = 0$, $R = +\infty$; if $\alpha = +\infty$, $R=0$.)
  Then $\sum c_n z^n$ converges if $\abs{z} < R$, and diverges if $\abs{z} > R$.
  (R is called the radius of convergence.)
  % Proof Omitted (Uses Root Test, Thm 3.33)
\end{theorem}

% --- MISSING EXAMPLES (Insert after Thm 3.39) ---

\begin{example}[Radius of Convergence Examples] % Examples following Thm 3.39
  \label{ex:chap3:radius_convergence_examples}
  Let us apply \autoref{thm:chap3:radius_convergence} to the following series:
  (a) $\sum n^n z^n$. Here $c_n = n^n$. $\sqrt[n]{\abs{c_n}} = n \to
  \infty$. So $\alpha = \infty$, $R=0$. The series converges only for $z=0$.
  (b) $\sum \frac{z^n}{n!}$. Here $c_n = 1/n!$. We know $n! \approx
  (n/e)^n \sqrt{2\pi n}$ (Stirling's formula), so $\sqrt[n]{1/n!}
  \approx \frac{e}{n} (2\pi n)^{-1/(2n)} \to 0$. Alternatively, using
  the ratio $\abs{c_{n+1}/c_n} = \frac{1/(n+1)!}{1/n!} =
  \frac{1}{n+1} \to 0$. Since the ratio limit is 0, the root limit is
  also 0 (\autoref{thm:chap3:limit_relation_tests}). So $\alpha = 0$,
  $R=+\infty$. The series converges for all $z \in \C$.
  (c) $\sum z^n$. Here $c_n = 1$. $\sqrt[n]{\abs{c_n}} = 1 \to 1$. So
  $\alpha = 1$, $R=1$. The series converges if $\abs{z} < 1$,
  diverges if $\abs{z} > 1$. (This is the geometric series,
  \autoref{thm:chap3:geometric_series}).
  (d) $\sum \frac{z^n}{n}$. Here $c_n = 1/n$. $\sqrt[n]{\abs{c_n}} =
  1/\sqrt[n]{n} \to 1$. So $\alpha=1$, $R=1$. Converges if $\abs{z} <
  1$, diverges if $\abs{z} > 1$. (Convergence on the circle
  $\abs{z}=1$ needs further tests).
  (e) $\sum \frac{z^n}{n^2}$. Here $c_n = 1/n^2$.
  $\sqrt[n]{\abs{c_n}} = (1/\sqrt[n]{n})^2 \to 1^2 = 1$. So
  $\alpha=1$, $R=1$. Converges if $\abs{z} < 1$, diverges if $\abs{z}
  > 1$. (Converges absolutely on $\abs{z}=1$ by comparison with
  p-series, \autoref{ex:chap3:p_series}).
\end{example}

% --- End of missing examples ---

\section{Summation by Parts}
\label{sec:chap3:summation_by_parts}

\begin{theorem}[Summation by Parts Formula] % Theorem 3.40
  \label{thm:chap3:summation_by_parts}
  Given two sequences $\sequence{a}$ and $\sequence{b}$. Let $A_n =
  \sum_{k=0}^n a_k$ if $n \ge 0$; put $A_{-1} = 0$. Then, if $0 \le p \le q$,
  \[ \sum_{n=p}^q a_n b_n = \sum_{n=p}^{q-1} A_n (b_n - b_{n+1}) +
  A_q b_q - A_{p-1} b_p. \]
  % Proof Omitted (Algebraic manipulation)
\end{theorem}

\begin{theorem}[Tests for Series Convergence - Abel/Dirichlet type] %
  % Theorem 3.41
  \label{thm:chap3:abel_dirichlet_tests}
  Suppose
  (a) the partial sums $A_n = \sum_{k=1}^n a_k$ form a bounded sequence;
  (b) $b_0 \ge b_1 \ge b_2 \ge \dots$;
  (c) $\lim_{n \to \infty} b_n = 0$.
  Then $\sum a_n b_n$ converges.
  (This is related to Dirichlet's test. Abel's test is similar but
  assumes $\sum a_n$ converges and $\sequence{b}$ is monotonic and convergent.)
  % Proof Omitted (Uses Summation by Parts, Thm 3.40)
\end{theorem}

% --- End of content chunk ---

% --- Content from Thm 3.42 to Thm 3.45 (Proofs Omitted) to append ---

\begin{theorem}[Alternating Series Test] % Theorem 3.42
  \label{thm:chap3:alternating_series_test}
  Suppose
  (a) $c_1 \ge c_2 \ge c_3 \ge \dots$;
  (b) $c_n \ge 0$ for $n=1, 2, 3, \dots$;
  (c) $\lim_{n \to \infty} c_n = 0$.
  Then the series $\sum_{n=1}^\infty (-1)^{n+1} c_n$ converges.
  % Proof Omitted (Uses properties of partial sums S_{2N}, S_{2N+1})
\end{theorem}

\section{Absolute Convergence}
\label{sec:chap3:absolute_convergence}

\begin{definition}[Absolute/Conditional Convergence] % Definition
  % 3.43 (Labeled 3.45 in Rudin 2nd Ed, but text is before Thm 3.44)
  \label{def:chap3:abs_cond_convergence}
  The series $\sum a_n$ is said to converge absolutely if the series
  $\sum \abs{a_n}$ converges.
  If $\sum a_n$ converges but $\sum \abs{a_n}$ diverges, the
  convergence is called conditional.
\end{definition}

\begin{theorem}[Absolute Convergence Implies Convergence] % Theorem
  % 3.44 (Labeled 3.46 in Rudin 2nd Ed)
  \label{thm:chap3:abs_conv_implies_conv}
  If $\sum a_n$ converges absolutely, then $\sum a_n$ converges.
  % Proof Omitted (Uses Cauchy criterion and triangle inequality |sum
  % a_k| <= sum |a_k|)
\end{theorem}

\section{Addition and Multiplication of Series}
\label{sec:chap3:series_ops}

\begin{theorem}[Algebraic Operations on Series] % Theorem 3.45
  % (Labeled 3.47 in Rudin 2nd Ed)
  \label{thm:chap3:series_algebra}
  If $\sum a_n = A$ and $\sum b_n = B$, then
  (a) $\sum (a_n + b_n) = A + B$, and
  (b) $\sum c \cdot a_n = c \cdot A$, for any fixed c.
  % Proof Omitted (Follows from limit properties of partial sums, Thm 3.3)
\end{theorem}

% --- End of content chunk ---

% --- Content from Def 3.46 to Thm 3.55 (Proofs Omitted) to append ---

\begin{definition}[Cauchy Product] % Definition 3.46 (Labeled 3.48 in
  % Rudin 2nd Ed)
  \label{def:chap3:cauchy_product}
  Given two series $\sum a_n$, $\sum b_n$, put
  \[ c_n = \sum_{k=0}^n a_k b_{n-k} \quad (n = 0, 1, 2, \dots). \]
  The series $\sum c_n$ is called the Cauchy product of the two series.
  (This definition is most useful when the two series are power series.)
\end{definition}

\begin{theorem}[Mertens' Theorem] % Theorem 3.47 (Labeled 3.50 in Rudin 2nd Ed)
  \label{thm:chap3:mertens_cauchy_product}
  Suppose
  (a) $\sum_{n=0}^\infty a_n$ converges absolutely
  (\autoref{def:chap3:abs_cond_convergence}),
  (b) $\sum_{n=0}^\infty a_n = A$,
  (c) $\sum_{n=0}^\infty b_n = B$,
  (d) $c_n = \sum_{k=0}^n a_k b_{n-k}$ ($n = 0, 1, 2, \dots$).
  Then
  \[ \sum_{n=0}^\infty c_n = AB. \]
  That is, the Cauchy product of two series converges to the product
  of their sums, provided that at least one of the series converges absolutely.
  (If both series converge conditionally, their Cauchy product need
  not converge.)
  % Proof Omitted
\end{theorem}

\section{Rearrangements}
\label{sec:chap3:rearrangements}

\begin{definition}[Rearrangement] % Definition 3.49 (Labeled 3.52 in
  % Rudin 2nd Ed)
  \label{def:chap3:rearrangement}
  Let $\sequence{k}$ be a sequence in which every positive integer
  appears exactly once (that is, $\sequence{k}$ is a 1-1 function
  from J onto J, a permutation of J). If $\sum a_n$ is a series and we define
  \[ a'_n = a_{k_n} \quad (n = 1, 2, 3, \dots), \]
  then the series $\sum a'_n$ is called a rearrangement of $\sum a_n$.
\end{definition}

% Note: Rudin discusses Riemann's theorem on conditionally convergent
% series here,
% but the next numbered theorem is about absolutely convergent series.

\begin{theorem}[Rearrangements of Absolutely Convergent Series] %
  % Theorem 3.55 in Rudin 3rd Ed
  \label{thm:chap3:rearrangement_abs_conv}
  If $\sum a_n$ converges absolutely, then every rearrangement $\sum
  a'_n$ converges, and they converge to the same sum.
  % Proof Omitted
\end{theorem}

% --- End of Chapter 3 content chunk (Proofs Omitted) ---
% --- End of chapters/chapter3.tex ---
